{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e723b7b7-02e1-4cda-8bae-cf56480c0d30",
   "metadata": {},
   "source": [
    "# ChArUco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821e32f-a411-490b-beff-cfbba9fa5e78",
   "metadata": {},
   "source": [
    "- ref: https://github.com/kyle-bersani/opencv-examples\n",
    "- don't use digital smoothing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ccd32b-b835-4c1d-b3ef-0d6dbbd4a356",
   "metadata": {},
   "source": [
    "- `ffmpeg -i _back.mp4 -vf \"crop=w=1440:h=1920:x=1440:y=0, transpose=2\" back.mp4`\n",
    "- `ffmpeg -i main.mp4 -map 0 -c copy -f segment -segment_time 60 -reset_timestamps 1 main_%03d.mp4`\n",
    "- `python get_intrinsics.py --vid ../data/record3d/tonpy-v8/raw/back.mp4 --squares 10 7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd71383e-95e7-4755-9914-7fbd83e72387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from utils import undistort\n",
    "\n",
    "\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_1000)\n",
    "charuco = aruco.CharucoBoard_create(\n",
    "        squaresX=10,\n",
    "        squaresY=7,\n",
    "        squareLength=0.039,\n",
    "        markerLength=0.0195,\n",
    "        dictionary=aruco_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c911a886-e2c4-4386-a2e2-de232e8e1041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 671/671 [00:14<00:00, 47.83it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('camera_raw.pkl', 'rb') as f:\n",
    "    (mtx, dist) = pickle.load(f)\n",
    "\n",
    "vid = imageio.mimread(\"../data/record3d/tonpy-v8/raw/back.mp4\", memtest=False)\n",
    "vid = undistort(vid, mtx, dist)\n",
    "\n",
    "with open('camera_undist.pkl', 'rb') as f:\n",
    "    (mtx, dist) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2946b3e-9af3-44ec-a58f-a1dd17c08ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip (t=0, ids=[[3]])\n",
      "skip (t=1, response=0)\n",
      "skip (t=2, response=0)\n",
      "skip (t=3, response=0)\n",
      "skip (t=4, response=0)\n",
      "skip (t=5, ids=[[17]])\n",
      "skip (t=6, ids=None)\n",
      "skip (t=7, response=0)\n",
      "skip (t=8, ids=[[8]])\n",
      "skip (t=9, ids=[[17]])\n",
      "skip (t=10, response=0)\n",
      "skip (t=11, response=0)\n",
      "skip (t=12, response=0)\n",
      "skip (t=13, response=1)\n",
      "skip (t=14, response=2)\n",
      "skip (t=15, ids=[[17]])\n",
      "skip (t=16, response=1)\n",
      "skip (t=17, ids=None)\n",
      "skip (t=18, response=0)\n",
      "skip (t=19, ids=[[17]])\n",
      "skip (t=20, ids=None)\n",
      "skip (t=21, response=0)\n",
      "skip (t=22, ids=None)\n",
      "skip (t=23, ids=[[22]])\n",
      "skip (t=24, ids=None)\n",
      "skip (t=25, response=1)\n",
      "skip (t=26, ids=None)\n",
      "skip (t=27, ids=[[37]])\n",
      "skip (t=28, response=0)\n",
      "skip (t=29, response=0)\n",
      "skip (t=30, ids=None)\n",
      "skip (t=31, response=0)\n",
      "skip (t=32, response=0)\n",
      "skip (t=33, ids=[[16]])\n",
      "skip (t=34, ids=[[22]])\n",
      "skip (t=35, response=0)\n",
      "skip (t=36, response=0)\n",
      "skip (t=37, ids=[[22]])\n",
      "skip (t=38, ids=[[517]])\n",
      "skip (t=39, response=0)\n",
      "skip (t=40, ids=[[930]])\n",
      "skip (t=41, ids=[[22]])\n",
      "skip (t=42, ids=[[22]])\n",
      "skip (t=43, ids=None)\n",
      "skip (t=44, ids=None)\n",
      "skip (t=45, ids=[[17]])\n",
      "skip (t=46, response=0)\n",
      "skip (t=47, ids=[[930]])\n",
      "skip (t=48, ids=[[431]])\n",
      "skip (t=49, ids=[[930]])\n",
      "skip (t=50, ids=[[466]])\n",
      "skip (t=51, response=0)\n",
      "skip (t=52, ids=[[22]])\n",
      "skip (t=53, response=0)\n",
      "skip (t=54, ids=[[3]])\n",
      "skip (t=55, ids=[[4]])\n",
      "skip (t=56, ids=[[22]])\n",
      "skip (t=57, response=0)\n",
      "skip (t=58, response=0)\n",
      "skip (t=59, response=0)\n",
      "skip (t=60, response=0)\n",
      "skip (t=61, response=1)\n",
      "skip (t=62, response=1)\n",
      "skip (t=63, response=0)\n",
      "skip (t=64, response=1)\n",
      "skip (t=65, response=3)\n",
      "skip (t=66, response=0)\n",
      "skip (t=67, response=1)\n",
      "skip (t=68, response=0)\n",
      "skip (t=69, response=0)\n",
      "skip (t=70, response=1)\n",
      "skip (t=71, response=0)\n",
      "skip (t=72, response=2)\n",
      "skip (t=73, response=3)\n",
      "skip (t=74, response=0)\n",
      "skip (t=75, response=3)\n",
      "skip (t=76, response=2)\n",
      "skip (t=77, response=4)\n",
      "skip (t=78, response=6)\n",
      "skip (t=79, response=1)\n",
      "skip (t=80, response=7)\n",
      "skip (t=81, response=6)\n",
      "skip (t=82, response=0)\n",
      "skip (t=83, response=2)\n",
      "skip (t=85, response=0)\n",
      "skip (t=86, response=1)\n",
      "skip (t=87, response=6)\n",
      "skip (t=88, response=4)\n",
      "skip (t=89, response=7)\n",
      "skip (t=90, response=5)\n",
      "skip (t=92, response=7)\n",
      "skip (t=98, response=6)\n",
      "skip (t=100, response=3)\n",
      "skip (t=102, response=3)\n",
      "skip (t=103, response=7)\n",
      "skip (t=104, response=5)\n",
      "skip (t=108, response=5)\n",
      "skip (t=111, response=5)\n",
      "skip (t=112, response=5)\n",
      "skip (t=114, response=2)\n",
      "skip (t=115, response=7)\n",
      "skip (t=117, response=7)\n",
      "skip (t=136, response=4)\n",
      "skip (t=144, response=6)\n",
      "skip (t=150, response=5)\n",
      "skip (t=200, response=5)\n",
      "skip (t=201, response=4)\n",
      "skip (t=203, response=6)\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "vid_sample, vid_paint, rvec_hist, tvec_hist = [], [], [], []\n",
    "\n",
    "for t, img in enumerate(vid[30:-30:3]):\n",
    "    bak = deepcopy(img)\n",
    "    img = deepcopy(img[...,::-1])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    aruco_params = aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=aruco_params)\n",
    "\n",
    "    corners, ids, rejectedImgPoints, recoveredIds = aruco.refineDetectedMarkers(\n",
    "            image = gray,\n",
    "            board = charuco,\n",
    "            detectedCorners = corners,\n",
    "            detectedIds = ids,\n",
    "            rejectedCorners = rejectedImgPoints,\n",
    "            cameraMatrix = mtx,\n",
    "            distCoeffs = dist)\n",
    "\n",
    "    img = aruco.drawDetectedMarkers(img, corners, borderColor=(0, 0, 255), ids=ids)\n",
    "\n",
    "    if not (ids is not None and len(ids) > 1):\n",
    "        print(\"skip (t={}, ids={})\".format(t, ids))\n",
    "        continue\n",
    "\n",
    "    response, charuco_corners, charuco_ids = aruco.interpolateCornersCharuco(\n",
    "            markerCorners=corners,\n",
    "            markerIds=ids,\n",
    "            image=gray,\n",
    "            board=charuco)\n",
    "\n",
    "    if response < 8:\n",
    "        print(\"skip (t={}, response={})\".format(t, response))\n",
    "        continue\n",
    "\n",
    "    # valid, rvec, tvec = aruco.estimatePoseCharucoBoard(\n",
    "    #         charucoCorners=charuco_corners,\n",
    "    #         charucoIds=charuco_ids,\n",
    "    #         board=charuco, \n",
    "    #         cameraMatrix=mtx,\n",
    "    #         distCoeffs=dist,\n",
    "    #         rvec=None,\n",
    "    #         tvec=None)\n",
    "    \n",
    "    objp = np.empty((0,3), np.float32)\n",
    "    for idx in charuco_ids:\n",
    "        objpi = np.dot(charuco.chessboardCorners[idx] - np.array([[5,7,0]]) * 0.04, np.array([[-1,0,0], [0,1,0], [0,0,-1]]))\n",
    "        objp = np.append(objp, objpi, axis=0)\n",
    "\n",
    "    valid, rvec, tvec = cv2.solvePnP(objp, charuco_corners, mtx, dist)\n",
    "\n",
    "    if not valid:\n",
    "        print(\"skip (t={}, valid={})\".format(t, valid))\n",
    "        continue\n",
    "\n",
    "    img = cv2.drawFrameAxes(img, mtx, dist, rvec, tvec, 0.3)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    vid_sample.append(bak)\n",
    "    vid_paint.append(img)\n",
    "    rvec_hist.append(rvec)\n",
    "    tvec_hist.append(tvec)\n",
    "\n",
    "print(len(vid_sample))\n",
    "imageio.mimwrite(\"temp.mp4\", vid_paint, macro_block_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15d280a-f929-44d8-b4ab-d87d8ab8a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimwrite(\"src/back_real.mp4\", vid_sample, macro_block_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f25572b-d199-4a27-a01a-df7f506da88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79802091-290e-416a-9d61-4f98501b0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 1920, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_paint[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d86d3e7-f39e-4fb3-89d8-cd572d090e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8409)\n"
     ]
    }
   ],
   "source": [
    "w = 1920\n",
    "h = 1440  # 1080\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "import json\n",
    "import torch\n",
    "\n",
    "os.makedirs('images/', exist_ok=True)\n",
    "\n",
    "out = {\n",
    "    \"fl_x\": float(mtx[0,0]),\n",
    "    \"fl_y\": float(mtx[1,1]),\n",
    "    \"cx\": float(mtx[0,2]),\n",
    "    \"cy\": float(mtx[1,2]),\n",
    "    \"w\": w,\n",
    "    \"h\": h,\n",
    "    \"camera_model\": 'OPENCV',\n",
    "    \"k1\": dist[0,0],\n",
    "    \"k2\": dist[0,1],\n",
    "    \"p1\": dist[0,2],\n",
    "    \"p2\": dist[0,3],\n",
    "}\n",
    "\n",
    "poses = []\n",
    "for t, (rvec, tvec) in enumerate(zip(rvec_hist, tvec_hist)):\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    T = tvec\n",
    "\n",
    "    c2w = np.eye(4)\n",
    "    c2w[:3,3] = np.dot(R.T, - T).squeeze()\n",
    "    c2w[:3,:3] = np.dot(R.T, np.array([[1,0,0], [0,-1,0], [0,0,-1]]))\n",
    "    poses.append(c2w)\n",
    "\n",
    "\n",
    "poses = torch.from_numpy(np.array(poses).astype(np.float32))\n",
    "print(torch.max(torch.abs(poses[:, :3, 3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd1cdd4-60f9-47c1-97c2-feca73d959ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_factor = 1.0\n",
    "# scale_factor /= torch.max(torch.abs(poses[:, :3, 3]))\n",
    "# print(scale_factor)\n",
    "# poses[:, :3, 3] *= scale_factor * self.config.scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd33318-892d-4be3-84af-ee33fda22255",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for t, (img, c2w) in enumerate(zip(vid_sample, poses)):\n",
    "    name = 'images/frame_{:05}.png'.format(t)\n",
    "    PIL.Image.fromarray(img).save(name, quality=95)  # heavy\n",
    "\n",
    "    frame = {\n",
    "        \"file_path\": name,\n",
    "        \"transform_matrix\": c2w.tolist(),\n",
    "    }\n",
    "    frames.append(frame)\n",
    "\n",
    "out[\"frames\"] = frames\n",
    "\n",
    "with open(\"transforms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(out, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c824de64-39f4-416d-b308-37d40973ce87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5d165-9aa9-4004-aa07-4f71398e25c4",
   "metadata": {},
   "source": [
    "```\n",
    "dataname/\n",
    "  ├ raw/\n",
    "  │   ├ back.mp4\n",
    "  │   └ main.mp4\n",
    "  └ colmap/\n",
    "      ├ images/\n",
    "      └ transforms.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce0f00-2ab6-48cb-89f9-fe662a7c13e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
